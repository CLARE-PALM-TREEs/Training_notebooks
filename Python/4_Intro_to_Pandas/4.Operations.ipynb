{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28deb9b9",
   "metadata": {},
   "source": [
    "<img src=\"images/Project_logos.png\" width=\"500\" height=\"300\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe44fe8",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e197f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set up an example DataFrame\n",
    "\n",
    "index_array = np.array(['Row 1', 'Row 2', 'Row 3', 'Row 4', 'Row 5', 'Row 6'])\n",
    "column_list = ('A', 'B', 'C', 'D')\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=index_array, columns=column_list)\n",
    "\n",
    "df.loc['Row 1', 'D'] = np.nan\n",
    "df.loc['Row 4', 'B'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c111c",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "You can calculate statistics over rows or columns. NaNs are ignored in the statistics calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f776366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean for each column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean for each row\n",
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f707eed",
   "metadata": {},
   "source": [
    "The missing values are not included in the calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d149fd5",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Calculate the sum of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space to complete the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223af597",
   "metadata": {},
   "source": [
    "### Applying functions\n",
    "You can apply your own functions to values or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to all values (x) in the DataFrame\n",
    "\n",
    "df.transform(lambda x: x + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to each column (x) in the DataFrame\n",
    "\n",
    "df.agg(lambda x: np.std(x) / 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5103784",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Multiply all values in `df` by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space to complete the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580672f2",
   "metadata": {},
   "source": [
    "### Rolling window operations\n",
    "It is possible to perform operations on rolling windows of data, e.g. calculating moving averages. More detailed information can be found at https://pandas.pydata.org/docs/user_guide/window.html#rolling-window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95989548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up example DataFrame\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\"Temperature at location A\": np.array([30.0, 29.6, 28.0, 31.2, 32.1, 27.4, 27.3, 27.8, 29.5, 29.8]),\n",
    "     \"Temperature at location B\": np.array([23.1, 22.4, 19.6, 20.5, 23.3, 23.2, 19.9, 20.2, 21.1, 20.8]),\n",
    "     \"Rainfall at location A\": np.array([5.0, 6.0, 1.0, 0.0, 0.6, 7.0, 4.3, 1.3, 11.5, 1.9]),\n",
    "     \"Rainfall at location B\": np.array([0.0, 0.0, 8.0, 11.2, 3.5, 0.0, 7.3, 2.8, 0.0, 0.2])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d928b2b",
   "metadata": {},
   "source": [
    "The keyword argument `window` specifies the size of the window. The following example calculates the rolling sum for a window size of 2. The default is for the resulting value to be assigned to the index at the end of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Rainfall at location A'].rolling(window=2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd3b52",
   "metadata": {},
   "source": [
    "The resulting value can instead be assigned to the index at the centre of the window by setting the `center` keyword to True. The following example calculates the rolling mean for a window size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Temperature at location B'].rolling(window=3, center=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f0af7",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "You can create a correlation matrix of correlations between a `DataFrame`'s columns using the `corr()` method (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html). There are options for the correlation method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8556f543",
   "metadata": {},
   "source": [
    "You can also calculate the correlation between `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = df2['Temperature at location B']\n",
    "series2 = df2['Rainfall at location B']\n",
    "\n",
    "series1.corr(series2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db992b86",
   "metadata": {},
   "source": [
    "### Joining DataFrames and Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f825346",
   "metadata": {},
   "source": [
    "You can join DataFrames that will extend the number of rows using ``concat``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(3, 5))\n",
    "df2 = pd.DataFrame(np.random.randn(4, 5))\n",
    "df3 = pd.DataFrame(np.random.randn(2, 5))\n",
    "\n",
    "df4 = pd.concat([df1, df2, df3])\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4363c",
   "metadata": {},
   "source": [
    "You can join DataFrames that will extend the number of columns using ``concat``, setting the axis to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(5, 2))\n",
    "df2 = pd.DataFrame(np.random.randn(5, 3))\n",
    "df3 = pd.DataFrame(np.random.randn(5, 4))\n",
    "\n",
    "df4 = pd.concat([df1, df2, df3], axis=1)\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ef299",
   "metadata": {},
   "source": [
    "You will notice that the resulting DataFrame keeps the index labels and column labels from the original DataFrames. This can be avoided by using ``ignore_index=True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2229e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.concat([df1, df2, df3], axis=1, ignore_index=True)\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time as dtt\n",
    "\n",
    "temp_df = pd.DataFrame(\n",
    "    {\"Station ID\": ['1', '1', '1', '2', '2', '3', '4', '4', '4', '4'],\n",
    "     \"Temperature\": [10, 14, 16, 15, 21, 17, 9, 11, 15, 7],\n",
    "     \"Time\": [dtt(3), dtt(6), dtt(9), dtt(6), dtt(12), dtt(9), dtt(3), dtt(6), dtt(9), dtt(12)]\n",
    "    }\n",
    ")\n",
    "\n",
    "precip_df = pd.DataFrame(\n",
    "    {\"Station ID\": ['1', '1', '2', '2', '3', '4', '4'],\n",
    "     \"Precipitation\": [0, 25, 0, 0, 36, 50, 0],\n",
    "     \"Time\": [dtt(3), dtt(6), dtt(6), dtt(9), dtt(6), dtt(3), dtt(9)]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db738bed",
   "metadata": {},
   "source": [
    "We can combine DataFrames using `merge`. \n",
    "\n",
    "The default is an inner join, which finds matches between the two DataFrames being merged. It will discard rows that donâ€™t match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.merge(precip_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0804cd4",
   "metadata": {},
   "source": [
    "We can choose to merge using an outer join, which aligns rows that have matches, but keeps remaining rows giving them a NaN value in the column where data is not there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c86763",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.merge(precip_df, how=\"outer\", on=[\"Station ID\", \"Time\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
